#!/usr/bin/env python3
"""
è°ƒè¯•å’Œä¿®å¤BERTæ¨¡å‹è¾“å‡ºæ ¼å¼é—®é¢˜
"""
import os
import warnings

warnings.filterwarnings('ignore')

# é…ç½®æ¸…åæº
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'


def debug_bert_output():
    """è°ƒè¯•BERTè¾“å‡ºæ ¼å¼"""
    try:
        from transformers import pipeline

        print("ğŸ” è°ƒè¯•BERTæ¨¡å‹è¾“å‡ºæ ¼å¼...")

        # åŠ è½½ä½ ç°åœ¨ä½¿ç”¨çš„æ¨¡å‹
        classifier = pipeline(
            "sentiment-analysis",
            model="cardiffnlp/twitter-xlm-roberta-base-sentiment",
            device=-1,
            cache_dir="./tsinghua_model_cache"
        )

        # æµ‹è¯•å‡ ä¸ªä¾‹å­ï¼ŒæŸ¥çœ‹è¾“å‡ºæ ¼å¼
        test_texts = [
            "æœŸå¾…æœ±ä¸€é¾™ï¼",
            "å°‘å¹´çƒ­è¡€ï¼Œæ‰¬å¸†èµ·èˆª",
            "666"
        ]

        for text in test_texts:
            print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬: {text}")
            try:
                result = classifier(text)
                print(f"   è¾“å‡ºç±»å‹: {type(result)}")
                print(f"   è¾“å‡ºå†…å®¹: {result}")

                # å°è¯•è§£æ
                if isinstance(result, list) and len(result) > 0:
                    print(f"   ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(result[0])}")
                    print(f"   ç¬¬ä¸€ä¸ªå…ƒç´ å†…å®¹: {result[0]}")

                    if isinstance(result[0], dict):
                        print(f"   æ ‡ç­¾: {result[0].get('label', 'N/A')}")
                        print(f"   åˆ†æ•°: {result[0].get('score', 'N/A')}")

            except Exception as e:
                print(f"   âŒ é”™è¯¯: {e}")

        return classifier

    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        return None


def robust_sentiment_analysis(text, classifier):
    """å¥å£®çš„æƒ…æ„Ÿåˆ†æå‡½æ•°"""
    try:
        # é¢„å¤„ç†
        text = text.strip()
        if len(text) < 2:
            return 0.5, 'neutral', 0.5

        # è°ƒç”¨BERT
        results = classifier(text)

        # å¥å£®çš„ç»“æœè§£æ
        label = None
        score = None

        if isinstance(results, list) and len(results) > 0:
            first_result = results[0]
            if isinstance(first_result, dict):
                label = first_result.get('label')
                score = first_result.get('score')
            elif isinstance(first_result, list) and len(first_result) > 0:
                # å¤šæ ‡ç­¾æƒ…å†µï¼Œå–åˆ†æ•°æœ€é«˜çš„
                best = max(first_result, key=lambda x: x.get('score', 0))
                label = best.get('label')
                score = best.get('score')
        elif isinstance(results, dict):
            label = results.get('label')
            score = results.get('score')

        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        if label is None or score is None:
            print(f"   âš ï¸ è§£æå¤±è´¥ï¼Œresultsæ ¼å¼: {type(results)} - {str(results)[:100]}...")
            return fallback_analysis(text)

        # æ ‡ç­¾æ ‡å‡†åŒ–
        label_clean = str(label).upper()

        # æƒ…æ„Ÿåˆ†æ•°è½¬æ¢
        if 'POSITIVE' in label_clean or 'POS' in label_clean:
            return float(score), 'positive', float(score)
        elif 'NEGATIVE' in label_clean or 'NEG' in label_clean:
            return 1 - float(score), 'negative', float(score)
        elif 'NEUTRAL' in label_clean:
            return 0.5, 'neutral', float(score)
        else:
            # æœªçŸ¥æ ‡ç­¾ï¼Œæ ¹æ®åˆ†æ•°æ¨æ–­
            if float(score) > 0.6:
                return float(score), 'positive', float(score)
            elif float(score) < 0.4:
                return 1 - float(score), 'negative', float(score)
            else:
                return 0.5, 'neutral', float(score)

    except Exception as e:
        print(f"   âŒ BERTåˆ†æå‡ºé”™: {str(e)[:50]}...")
        return fallback_analysis(text)


def fallback_analysis(text):
    """å¤‡ç”¨åˆ†ææ–¹æ³•"""
    import jieba

    # ç®€å•çš„å…³é”®è¯åˆ†æ
    pos_keywords = ['æœŸå¾…', 'ç¾', 'æ£’', 'å¥½', 'èµ', 'æ”¯æŒ', '666', 'çƒ­è¡€', 'æ‰¬å¸†èµ·èˆª']
    neg_keywords = ['å·®', 'å', 'å¤±æœ›', 'çƒ‚']

    words = jieba.lcut(text)

    pos_score = sum(1 for word in words if any(pk in word for pk in pos_keywords))
    neg_score = sum(1 for word in words if any(nk in word for nk in neg_keywords))

    # ç‰¹æ®Šè§„åˆ™
    if '666' in text:
        return 0.85, 'positive', 0.85
    if 'æœŸå¾…' in text and ('ï¼' in text or '!' in text):
        return 0.9, 'positive', 0.9
    if 'çƒ­è¡€' in text:
        return 0.88, 'positive', 0.88

    total = pos_score + neg_score
    if total == 0:
        return 0.5, 'neutral', 0.5

    sentiment_score = pos_score / total
    if sentiment_score > 0.6:
        return sentiment_score, 'positive', sentiment_score
    elif sentiment_score < 0.4:
        return sentiment_score, 'negative', 1 - sentiment_score
    else:
        return 0.5, 'neutral', 0.5


def run_fixed_analysis():
    """è¿è¡Œä¿®å¤åçš„åˆ†æ"""
    from utils.getPublicData import getAllCommentData

    print("ğŸš€ è¿è¡Œä¿®å¤åçš„æƒ…æ„Ÿåˆ†æ...")

    # è°ƒè¯•æ¨¡å‹è¾“å‡º
    classifier = debug_bert_output()

    if classifier is None:
        print("âŒ æ— æ³•åŠ è½½BERTæ¨¡å‹ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
        return

    # è·å–æ•°æ®
    commentsList = getAllCommentData()

    # åˆ†æå‰å‡ æ¡ï¼Œç¡®è®¤ä¿®å¤æ•ˆæœ
    print(f"\nğŸ“Š åˆ†æå‰10æ¡è¯„è®ºï¼ŒéªŒè¯ä¿®å¤æ•ˆæœ:")
    print("=" * 80)

    for i in range(min(10, len(commentsList))):
        text = commentsList[i][5]
        score, label, confidence = robust_sentiment_analysis(text, classifier)

        print(f"{i + 1:2d} | {score:5.3f} | {label:8s} | {text[:50]}")

    print("\nâœ… å¦‚æœä¸Šé¢çš„ç»“æœæ­£å¸¸æ˜¾ç¤ºï¼Œè¯´æ˜é—®é¢˜å·²ä¿®å¤ï¼")
    print("ç°åœ¨å¯ä»¥è¿è¡Œå®Œæ•´çš„åˆ†æäº†ã€‚")

    return classifier


if __name__ == "__main__":
    classifier = run_fixed_analysis()